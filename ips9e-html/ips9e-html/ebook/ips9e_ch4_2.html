<!DOCTYPE html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
    <title>ips9e_ch4</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
                    <link href="css/boilerplate.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/jquery-ui-custom.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/manuscript.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/digfir_ebook_fw.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/ips9e.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/ips9e_ch4.css" media="screen" rel="stylesheet" type="text/css" >    
    
    </head>
<body class="noUi">
<div id="manuscript" data-chapter-number="4">
    <div data-type="section" data-block_type="h1" id="ips9e-ch04-sec1-01" level="1" data-print_page="215">
<h2 class="section-title">
<span data-type="number">4.1</span> <span data-type="title" data-title-for="ips9e-ch04-sec1-01">4.1 Randomness
</span>
</h2>

<div data-type="box" data-block_type="SP" id="ips9e-ch04-box-02"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="ips9e-ch04-box-02"></h3>
<div data-block_type="SP-TXT-ni" id="ips9e-ch04-p-10"><p>When you complete this section, you will be able to:</p></div>
<ul data-block_type="bluebullet" id="ips9e-ch04-list-02">
<li><div data-block_type="SP-BL-first" id="ips9e-ch04-p-11"><p><span data-block_type="maker">•</span> Identify random phenomena.</p></div></li>
<li><div data-block_type="SP-BL-mid" id="ips9e-ch04-p-12"><p><span data-block_type="maker">•</span> Interpret the term “probability” for particular examples.</p></div></li>
<li><div data-block_type="SP-BL-last" id="ips9e-ch04-p-13"><p><span data-block_type="maker">•</span> Identify trials as independent or not.</p></div></li>
</ul>
</div></div>
<div data-margin-content="left" data-block_type="page_start" id="ips9e_page_216"><p>216</p></div>
<div data-block_type="TXT-ni" id="ips9e-ch04-p-14"><p>Toss a coin, or choose a simple random sample (SRS). The result can’t be predicted in advance because the result will vary when you toss the coin or choose the sample repeatedly. But there is, nonetheless, a regular pattern in the results, a pattern that emerges clearly only after many repetitions. This remarkable fact is the basis for the idea of probability.</p></div>
<div data-type="box" data-block_type="EXP" data-filename="example_4_1.html" id="ips9e-ch04-box-03"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="ips9e-ch04-box-03"></h3>
<div data-block_type="EXP-N" id="ips9e-ch04-p-15"><p>EXAMPLE 4.1</p></div>
<div data-block_type="EXP-TXT-first" id="ips9e-ch04-p-16"><p><span data-block_type="EXP-T-ri">Toss a coin 5000 times.</span> When you toss a coin, there are only two possible outcomes, heads or tails. <span data-type="link" data-href="figure_4_1.html">Figure 4.1</span> shows the results of tossing a coin 5000 times twice (Trial A and Trial B). For each number of tosses from 1 to 5000, we have plotted the proportion of those tosses that gave a head.</p></div>
<div data-type="figure" data-caption-compass="S" data-filename="figure_4_1.html" data-figure-id="ips9e-ch04-fig-02" data-block_type="FIGURE" data-layout-align="center" data-layout-width="medium" data-layout-border="false">

<img id="" src="asset/ch4/17MOOREIPS-MSE_9e_fig_04_01.jpg" data-figure-id="ips9e-ch04-fig-02" data-layout-width="medium" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 4.1: </span><span data-type="caption"><span data-block_type="FG-N-ri">Figure 4.1</span> <span data-block_type="FG-CAP">The proportion of tosses of a coin that give a head varies as we make more tosses. Eventually, however, the proportion approaches 0.5, the probability of a head. This figure shows the results of two trials of 5000 tosses each, <span data-type="link" data-href="example_4_1.html">Example 4.1</span>.</span></span>
</div>
</div>
<div data-block_type="EXP-TXT-ni" id="ips9e-ch04-p-17"><p>Trial A (red line) begins tail, head, tail, tail. You can see that the proportion of heads for Trial A starts at 0 on the first toss, rises to 0.5 when the second toss gives a head, then falls to 0.33 and 0.25 as we get two more tails. Trial B (blue dotted line), on the other hand, starts with five straight heads, so the proportion of heads is 1 until the sixth toss.</p></div>
<div data-block_type="EXP-TXT-ni" id="ips9e-ch04-p-18"><p>The proportion of tosses that produce heads is quite variable at first. Trial A starts low and Trial B starts high. As we make more and more tosses, however, the proportion of heads for each trial gets close to 0.5 and stays there.</p></div>
<div data-block_type="EXP-TXT-ni" id="ips9e-ch04-p-19"><p>If we made yet a third trial at tossing the coin a great many times, the proportion of heads would again settle down to 0.5 in the long run. We say that 0.5 is the <span data-type="termref" data-term="probability"><strong>probability</strong></span><span data-block_type="MN-GL-term">probability</span> of a head. The probability 0.5 appears as a horizontal line on the graph.</p></div>
</div></div>
<div data-margin-content="right" data-block_type="page_start" id="ips9e_page_217"><p>217</p></div>
<div data-block_type="Applet icon" id="ips9e-ch04-p-20"><p><img id="" src="asset/global_images/BPSapplet-icon.jpg" data-figure-id="" data-layout-width="" data-mmtype="" alt="image"></p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-21"><p>The <em>Probability</em> applet on the text website animates <span data-type="link" data-href="figure_4_1.html">Figure 4.1</span>. It allows you to choose the probability of a head and simulate any number of tosses of a coin with that probability. Try it. You will see that the proportion of heads gradually settles down close to the chosen probability. Equally important, you will also see that the proportion in a small or moderate number of tosses can be far from this probability. <em>Probability describes only what happens in the long run. Most people expect chance outcomes to show more short-term regularity than is actually true.</em></p></div>
<div data-block_type="Caution icon" id="ips9e-ch04-p-22"><p><img id="" src="asset/global_images/BPScaution-icon.jpg" data-figure-id="" data-layout-width="" data-mmtype="" alt="image"></p></div>
<div data-type="box" data-block_type="EXP" data-filename="example_4_2.html" id="ips9e-ch04-box-04"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="ips9e-ch04-box-04"></h3>
<div data-block_type="EXP-N" id="ips9e-ch04-p-23"><p>EXAMPLE 4.2</p></div>
<div data-block_type="EXP-TXT-first" id="ips9e-ch04-p-24"><p><span data-block_type="EXP-T-ri">Significance testing and Type I errors.</span> In <span data-type="link" data-href="ips9e-ch06.xml">Chapter 6</span>, we will learn about significance testing and Type I errors. When we perform a significance test, we have the possibility of making a Type I error under certain circumstances. The significance-testing procedure is set up so that the probability of making this kind of error is small, usually 5%. If we perform a large number of significance tests under this set of circumstances, the proportion of times that we will make a Type I error is 0.05.</p></div>
</div></div>
<div data-block_type="TXT" id="ips9e-ch04-p-25"><p>In the coin toss setting, the probability of a head is a characteristic of the coin being tossed. A coin is called <span data-type="termref" data-term="fair"><strong>fair</strong></span><span data-block_type="MN-GL-term">fair coin</span> if the probability of a head is 0.5; that is, it is equally likely to come up heads or tails. If we toss a coin five times and it comes up heads for all five tosses, we might suspect that the coin is not fair. Is this outcome likely if, in fact, the coin is fair? This is what happened in Trials A and B of <span data-type="link" data-href="example_4_1.html">Example 4.1</span>. We will learn a lot more about significance testing in later chapters. For now, we are content with some very general ideas.</p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-26"><p>When the Type I error of a statistical significance procedure is set at 0.05, this probability is a characteristic of the procedure. If we roll a pair of dice once, we do not know whether the sum of the faces will be seven or not. Similarly, if we perform a significance test once, we do not know if we will make a Type I error or not. However, if the procedure is designed to have a Type I error probability of 0.05, then we are much less likely than not to make a Type I error.</p></div>
<div data-block_type="level_2_title" id="ips9e-ch04-p-27"><p><span data-block_type="h2">The language of probability</span></p></div>
<div data-block_type="TXT-ni" id="ips9e-ch04-p-28"><p>“Random” in statistics is not a synonym for “unpredictable” but a description of a kind of order that emerges in the long run. We often encounter the unpredictable side of randomness in our everyday experience, but we rarely see enough repetitions of the same random phenomenon to observe the long-term regularity that probability describes. You can see that regularity emerging in <span data-type="link" data-href="figure_4_1.html">Figure 4.1</span>. In the very long run, the proportion of tosses that give a head is 0.5. This is the intuitive idea of probability. Probability 0.5 means “occurs half the time in a very large number of trials.”</p></div>
<div data-type="box" data-block_type="BX1" id="ips9e-ch04-box-05"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="ips9e-ch04-box-05"></h3>
<div data-block_type="BX1-T" id="ips9e-ch04-p-29"><p>RANDOMNESS AND PROBABILITY</p></div>
<div data-block_type="BX1-TXT-ni" id="ips9e-ch04-p-30"><p>We call a phenomenon <strong>random</strong> if individual outcomes are uncertain but there is, nonetheless, a regular distribution of outcomes in a large number of repetitions.</p></div>
<div data-block_type="BX1-TXT" id="ips9e-ch04-p-31"><p>The <strong>probability</strong> of any outcome of a random phenomenon is the proportion of times the outcome would occur in a very long series of repetitions.</p></div>
</div></div>
<div data-margin-content="left" data-block_type="page_start" id="ips9e_page_218"><p>218</p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-32"><p>Not all coins are fair. In fact, most real coins have bumps and imperfections that make the probability of heads a little different from 0.5. The probability might be 0.499999 or 0.500002. For our study of probability in this chapter, we will assume that we know the actual values of probabilities. Thus, we assume things like fair coins, even though we know that real coins are not exactly fair. We do this to learn what kinds of outcomes we are likely to see when we make such assumptions. When we study statistical inference in later chapters, we look at the situation from the opposite point of view: given that we have observed certain outcomes, what can we say about the probabilities that generated these outcomes?</p></div>
<div data-type="box" data-block_type="EXR" id="ips9e-ch04-box-06"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="ips9e-ch04-box-06"></h3>
<div data-block_type="EXR-H" id="ips9e-ch04-p-33"><p>USE YOUR KNOWLEDGE</p></div>
<div data-type="question" data-block_type="exercise_4_1.html" id="ips9e-ch04-ques-01">
<h3>Question
			    <span data-type="number">4.1 </span><span data-type="title"></span>
</h3>
<div data-block_type="EXR-QUE-NL-first" id="ips9e-ch04-p-34"><p><span data-block_type="EXR-QUE-N-ri">4.1</span> <span data-block_type="EXR-QUE-T-ri">Use Table B.</span> We can use the random digits in <span data-type="link" data-href="table_b.html">Table B</span> in the back of the book to simulate tossing a fair coin. Start at line 131 and read the numbers from left to right. If the number is 0, 2, 4, 6, or 8, you will say that the coin toss resulted in a head; if the number is a 1, 3, 5, 7, or 9, the outcome is tails. Use the first 10 random digits on line 131 to simulate 10 tosses of a fair coin. What is the actual proportion of heads in your simulated sample? Explain why you did not get exactly five heads.</p></div>
</div>
</div></div>
<div data-block_type="TXT" id="ips9e-ch04-p-35"><p>Probability describes what happens in very many trials, and we must actually observe many trials to pin down a probability. In the case of tossing a coin, some diligent people have in fact made thousands of tosses.</p></div>
<div data-type="box" data-block_type="EXP" data-filename="example_4_3.html" id="ips9e-ch04-box-07"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="ips9e-ch04-box-07"></h3>
<div data-block_type="EXP-N" id="ips9e-ch04-p-36"><p>EXAMPLE 4.3</p></div>
<div data-block_type="EXP-TXT-first" id="ips9e-ch04-p-37"><p><span data-block_type="EXP-T-ri">Many tosses of a coin.</span> The French naturalist Count Buffon (1707–1788) tossed a coin 4040 times. Result: 2048 heads, or proportion 2048/4040 = 0.5069 for heads.</p></div>
<div data-block_type="EXP-TXT-ni" id="ips9e-ch04-p-38"><p>Around 1900, the English statistician Karl Pearson heroically tossed a coin 24,000 times. Result: 12,012 heads, a proportion of 0.5005.</p></div>
<div data-block_type="EXP-TXT-ni" id="ips9e-ch04-p-39"><p>While imprisoned by the Germans during World War II, the South African statistician John Kerrich tossed a coin 10,000 times. Result: 5067 heads, proportion of heads 0.5067.</p></div>
</div></div>
<div data-block_type="level_2_title" id="ips9e-ch04-p-40"><p><span data-block_type="h2">Thinking about randomness</span></p></div>
<div data-block_type="TXT-ni" id="ips9e-ch04-p-41"><p>That some things are random is an observed fact about the world. The outcome of a coin toss, the time between emissions of particles by a radioactive source, and the sexes of the next litter of lab rats are all random. So is the outcome of a random sample or a randomized experiment. Probability theory is the branch of mathematics that describes random behavior. Of course, we can never observe a probability exactly. We could always continue tossing the coin, for example. Mathematical probability is an idealization based on imagining what would happen in an indefinitely long series of trials.</p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-42"><p>The best way to understand randomness is to observe random behavior—not only the long-run regularity but the unpredictable results of short runs. You can do this with physical devices such as coins and dice, but software simulations of random behavior allow faster exploration. As you explore randomness, remember:</p></div>
<ul data-block_type="bullet" id="ips9e-ch04-list-03">
<li><div data-block_type="BL-first" id="ips9e-ch04-p-43"><p><span data-block_type="maker">•</span> You must have a long series of <span data-type="termref" data-term="independent"><strong>independent</strong></span><span data-block_type="MN-GL-term">independence</span> trials. That is, the outcome of one trial must not influence the outcome of any other. Imagine a crooked gambling house where the operator of a roulette wheel can stop it where she chooses—she can prevent the proportion of “red” from settling down to a fixed number. These trials are not independent.</p></div>
<div data-margin-content="right" data-block_type="page_start" id="ips9e_page_219"><p>219</p></div>
</li>
<li><div data-block_type="BL" id="ips9e-ch04-p-44"><p><span data-block_type="maker">•</span> The idea of probability is empirical. Simulations start with given probabilities and imitate random behavior, but we can estimate a real-world probability only by actually observing many trials.</p></div></li>
<li><div data-block_type="BL-last" id="ips9e-ch04-p-45"><p><span data-block_type="maker">•</span> Nonetheless, simulations are very useful because we need long runs of trials. In situations such as coin tossing, the proportion of an outcome often requires several hundred trials to settle down to the probability of that outcome. The kinds of physical random devices suggested in the exercises are too slow to make performing so many trials practical. Short runs give only rough estimates of a probability.</p></div></li>
</ul>
<div data-block_type="level_2_title" id="ips9e-ch04-p-46"><p><span data-block_type="h2">The uses of probability</span></p></div>
<div data-block_type="TXT-ni" id="ips9e-ch04-p-47"><p>Probability theory originated in the study of games of chance. Tossing dice, dealing shuffled cards, and spinning a roulette wheel are examples of deliberate randomization. In that respect, they are similar to random sampling. Although games of chance are ancient, they were not studied by mathematicians until the sixteenth and seventeenth centuries.</p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-48"><p>It is only a mild simplification to say that probability as a branch of mathematics arose when seventeenth-century French gamblers asked the mathematicians Blaise Pascal and Pierre de Fermat for help. Gambling is still with us, in casinos and state lotteries. We will make use of games of chance as simple examples that illustrate the principles of probability.</p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-49"><p>Careful measurements in astronomy and surveying led to further advances in probability in the eighteenth and nineteenth centuries because the results of repeated measurements are random and can be described by distributions much like those arising from random sampling. Similar distributions appear in data on human life span (mortality tables) and in data on lengths or weights in a population of skulls, leaves, or cockroaches.<span data-type="termref" data-term="fn_ch4_fn1"><sup>1</sup></span></p></div>
<div data-block_type="TXT" id="ips9e-ch04-p-50"><p>Now, we employ the mathematics of probability to describe the flow of traffic through a highway system, the Internet, or a computer processor; the genetic makeup of individuals or populations; the energy states of subatomic particles; the spread of epidemics or tweets; and the rate of return on risky investments. Although we are interested in probability because of its usefulness in statistics, the mathematics of chance is important in many fields of study.</p></div>
</div>
<!-- #x-digfir-subsection-insertion-point --></div><!-- /#manuscript -->
<br class="clear" />
<!-- end of material in original view -->

	<!--[if IE]><script type="text/javascript" src="js/excanvas.compiled.js"></script><![endif]-->
    
<script type="text/javascript" src="js/utilities.js"></script>
<script type="text/javascript" src="js/query_types.js"></script>
<script type="text/javascript" src="js/player.js"></script>
<script type="text/javascript" src="js/jquery.js"></script>
<script type="text/javascript" src="js/jquery-ui-1.8.16.custom.min.js"></script>
<script type="text/javascript" src="js/jquery_extensions.js"></script>
<script type="text/javascript" src="js/swfobject.js"></script>
<script type="text/javascript" src="http://admin.brightcove.com/js/BrightcoveExperiences.js"></script>
<script type="text/javascript" src="js/digfir_ebook_fw.js"></script>
<script type="text/javascript" src="js/ips9e.js"></script>
<script type="text/javascript" src="js/ips9e_ch4.js"></script>
<script type="text/javascript">
    //<!--
    
$(window).ready(function () {
	player.initialize('5732604a757a2e2770000002');
});
    //-->
</script>
</body>
</html>

